{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from definitions import get_node_color, get_node_id\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append(\"./..\")\n",
    "from cell_graph import Cell_Graph\n",
    "from soft_wl_subtree import Soft_WL_Subtree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Discovery set from Danenberg_et_al\n",
    "* 1) data filtering: exclude patients with no clinical data and images with less than 500 cells\n",
    "* 2) Random partition: for reproducibility purpose, we use a random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initially,\n",
      "718 patients (794 images) with cell data, 2604 patients with clinical data, \n",
      "\n",
      "Remove images without invasive tumor,\n",
      "693 patients (749 images) with cell data, 2604 patients with clinical data, \n",
      "\n",
      "Remove patients with no clinical data,\n",
      "683 patients (737 images) with cell data and clinical data, \n",
      "\n",
      "Remove images with less than 500 cells\n",
      "579 patients (621 images) with more than 500 cells and clinical data, \n",
      "\n",
      "After splitting into discovery and validation sets,\n",
      "379 patients (404 images) with more than 500 cells and clinical data in the discovery set, \n"
     ]
    }
   ],
   "source": [
    "# read single cell data and clinical data\n",
    "cells = pd.read_csv(\"Datasets/Danenberg_et_al/cells.csv\")\n",
    "clinical = pd.read_csv(\"Datasets/Danenberg_et_al/clinical.csv\")\n",
    "print(\"Initially,\")\n",
    "print(\n",
    "    \"{} patients ({} images) with cell data, {} patients with clinical data, \".format(\n",
    "        len(cells[\"metabric_id\"].unique()),\n",
    "        len(cells[\"ImageNumber\"].unique()),\n",
    "        len(clinical[\"metabric_id\"].unique()),\n",
    "    )\n",
    ")\n",
    "# remove images without invasive tumor\n",
    "print(\"\\nRemove images without invasive tumor,\")\n",
    "cells = cells.loc[cells.isTumour == 1]\n",
    "print(\n",
    "    \"{} patients ({} images) with cell data, {} patients with clinical data, \".format(\n",
    "        len(cells[\"metabric_id\"].unique()),\n",
    "        len(cells[\"ImageNumber\"].unique()),\n",
    "        len(clinical[\"metabric_id\"].unique()),\n",
    "    )\n",
    ")\n",
    "# remove patients with no clinical data\n",
    "print(\"\\nRemove patients with no clinical data,\")\n",
    "cells = cells.loc[cells[\"metabric_id\"].isin(clinical[\"metabric_id\"])]\n",
    "print(\n",
    "    \"{} patients ({} images) with cell data and clinical data, \".format(\n",
    "        len(cells[\"metabric_id\"].unique()),\n",
    "        len(cells[\"ImageNumber\"].unique()),\n",
    "    )\n",
    ")\n",
    "# remove images with less than 500 cells\n",
    "print(\"\\nRemove images with less than 500 cells\")\n",
    "cells_per_image = cells.groupby(\"ImageNumber\").size()\n",
    "cells = cells.loc[\n",
    "    cells[\"ImageNumber\"].isin(cells_per_image[cells_per_image > 500].index)\n",
    "]\n",
    "clinical = clinical.loc[clinical[\"metabric_id\"].isin(cells[\"metabric_id\"].unique())]\n",
    "print(\n",
    "    \"{} patients ({} images) with more than 500 cells and clinical data, \".format(\n",
    "        len(cells[\"metabric_id\"].unique()),\n",
    "        len(cells[\"ImageNumber\"].unique()),\n",
    "    )\n",
    ")\n",
    "\n",
    "random.seed(0)\n",
    "Subset_id = [1] * (len(clinical) - 200) + [2] * 200\n",
    "random.shuffle(Subset_id)\n",
    "clinical['Subset_id'] = Subset_id\n",
    "cells_discovery = cells.loc[cells[\"metabric_id\"].isin(clinical.loc[clinical['Subset_id'] == 1, \"metabric_id\"])]\n",
    "cells_validation = cells.loc[cells[\"metabric_id\"].isin(clinical.loc[clinical['Subset_id'] == 2, \"metabric_id\"])]\n",
    "print(\"\\nAfter splitting into discovery and validation sets,\")\n",
    "print(\n",
    "    \"{} patients ({} images) with more than 500 cells and clinical data in the discovery set, \".format(\n",
    "        len(cells_discovery[\"metabric_id\"].unique()),\n",
    "        len(cells_discovery[\"ImageNumber\"].unique()),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize data, and Generate cellular graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign cell type Id based on meta description column\n",
    "cells['cellTypeID'] = cells['meta_description'].map(get_node_id('Danenberg', 'CellType'))\n",
    "# standardize column names\n",
    "patientID_colname = \"metabric_id\"\n",
    "imageID_colname = \"ImageNumber\"\n",
    "celltypeID_colname = \"cellTypeID\"\n",
    "coorX_colname = \"Location_Center_X\"\n",
    "coorY_colname = \"Location_Center_Y\"\n",
    "cells = cells.rename(\n",
    "            columns={\n",
    "                patientID_colname: \"patientID\",\n",
    "                imageID_colname: \"imageID\",\n",
    "                celltypeID_colname: \"celltypeID\",\n",
    "                coorX_colname: \"coorX\",\n",
    "                coorY_colname: \"coorY\",\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: patient MB-0190 has 2 images.\n",
      "Warning: patient MB-0442 has 2 images.\n",
      "Warning: patient MB-0321 has 2 images.\n",
      "Warning: patient MB-0317 has 2 images.\n",
      "Warning: patient MB-0353 has 2 images.\n",
      "Warning: patient MB-0354 has 2 images.\n",
      "Warning: patient MB-0573 has 2 images.\n",
      "Warning: patient MB-0361 has 2 images.\n",
      "Warning: patient MB-0081 has 2 images.\n",
      "Warning: patient MB-0322 has 2 images.\n",
      "Warning: patient MB-0325 has 2 images.\n",
      "Warning: patient MB-0545 has 2 images.\n",
      "Warning: patient MB-0269 has 2 images.\n",
      "Warning: patient MB-0551 has 2 images.\n",
      "Warning: patient MB-0260 has 2 images.\n",
      "Warning: patient MB-0359 has 2 images.\n",
      "Warning: patient MB-0609 has 2 images.\n",
      "Warning: patient MB-0126 has 2 images.\n",
      "Warning: patient MB-0138 has 2 images.\n",
      "Warning: patient MB-0135 has 2 images.\n",
      "Warning: patient MB-0158 has 2 images.\n",
      "Warning: patient MB-0167 has 2 images.\n",
      "Warning: patient MB-0151 has 2 images.\n",
      "Warning: patient MB-0175 has 2 images.\n",
      "Warning: patient MB-0177 has 2 images.\n",
      "Warning: patient MB-0184 has 2 images.\n",
      "Warning: patient MB-0188 has 2 images.\n",
      "Warning: patient MB-0206 has 2 images.\n",
      "Warning: patient MB-0195 has 2 images.\n",
      "Warning: patient MB-0200 has 2 images.\n",
      "Warning: patient MB-0203 has 2 images.\n",
      "Warning: patient MB-0384 has 2 images.\n",
      "Warning: patient MB-0373 has 2 images.\n",
      "Warning: patient MB-0399 has 2 images.\n",
      "Warning: patient MB-0538 has 2 images.\n",
      "Warning: patient MB-0438 has 2 images.\n",
      "Warning: patient MB-0412 has 2 images.\n",
      "Warning: patient MB-0431 has 2 images.\n",
      "Warning: patient MB-0490 has 2 images.\n",
      "Warning: patient MB-0583 has 2 images.\n",
      "Warning: patient MB-0145 has 2 images.\n",
      "Warning: patient MB-0336 has 2 images.\n",
      "There are 579 patients/cell graphs\n",
      "The first cell graph is a tuple with 3 elements: (patient_id, graph, cell_types)\n",
      "\tThe first element is the patient id: MB-0282\n",
      "\tThe second element is the adjacnecy matrix, with the shape of (1624, 1624)\n",
      "\tThe third element is the cell types, with the shape of (1624,)\n",
      "There are 1624 cells with 28 unique cell types\n"
     ]
    }
   ],
   "source": [
    "cell_graph_ = Cell_Graph(a = 0.01)\n",
    "Cell_graphs = cell_graph_.generate(cells)\n",
    "print(\"There are {} patients/cell graphs\".format(len(Cell_graphs)))\n",
    "\n",
    "\n",
    "cell_graph = Cell_graphs[0]\n",
    "print(\"The first cell graph is a tuple with 3 elements: (patient_id, graph, cell_types)\")\n",
    "print(\"\\tThe first element is the patient id: {}\".format(cell_graph[0]))\n",
    "print(\"\\tThe second element is the adjacnecy matrix, with the shape of {}\".format(cell_graph[1].shape))\n",
    "print(\"\\tThe third element is the cell types, with the shape of {}\".format(cell_graph[2].shape))\n",
    "print(\n",
    "        \"There are {} cells with {} unique cell types\".format(\n",
    "            cell_graph[1].shape[0], np.unique(cell_graph[2]).shape[0]\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify TME patterns with Soft WL subtree kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cis/home/zwang/.bashrc: line 40: /cis/home/zwang/.local/bin/virtualenvwrapper.sh: No such file or directory\n",
      "Initialize SoftWL: n_iter=2, n_jobs=-1, k=100, normalize=True\n",
      "Discovering TME patterns from 579 graphs, median number of nodes is 1475.0, node feature matrix dimension is (1624,)\n",
      "\t 1) Graph Convolution\n",
      "\t 2) Clustering Subtrees\n",
      "Finding 100 nearest neighbors using minkowski metric and 'auto' algorithm\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 37.2435518    7.58074535  80.02412017 ...  29.06080497  51.91345629\n 151.36154659].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m export OMP_NUM_THREADS=1 # to avoid the insufficient memory error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m soft_wl_subtree_ \u001b[38;5;241m=\u001b[39m Soft_WL_Subtree(\n\u001b[1;32m      3\u001b[0m             n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[1;32m      4\u001b[0m         )\n\u001b[0;32m----> 5\u001b[0m Cell_graphs_prime, Signatures \u001b[38;5;241m=\u001b[39m \u001b[43msoft_wl_subtree_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiscover_patterns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCell_graphs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere are \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m discovered patterns\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(Signatures)))\n\u001b[1;32m      7\u001b[0m cell_graph_prime \u001b[38;5;241m=\u001b[39m Cell_graphs_prime[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Projects/BiGraph4TME/Demo/./../soft_wl_subtree.py:152\u001b[0m, in \u001b[0;36mdiscover_patterns\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    148\u001b[0m     N_nodes\u001b[38;5;241m.\u001b[39mappend(subtree_feature\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# append the number of nodes\u001b[39;00m\n\u001b[1;32m    149\u001b[0m Subtree_features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[1;32m    150\u001b[0m     Subtree_features, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    151\u001b[0m )  \u001b[38;5;66;03m# concatenate all subtree features\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m 2) Clustering Subtrees\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    153\u001b[0m Pattern_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcluster_subtrees(\n\u001b[1;32m    154\u001b[0m     Subtree_features\n\u001b[1;32m    155\u001b[0m )  \u001b[38;5;66;03m# cluster the subtree features\u001b[39;00m\n\u001b[1;32m    156\u001b[0m Signatures \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_cluster_centroids(\n\u001b[1;32m    157\u001b[0m     Subtree_features, Pattern_ids\n\u001b[1;32m    158\u001b[0m )  \u001b[38;5;66;03m# compute the cluster centroids --> signature of each TME pattern\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/BiGraph4TME/Demo/./../soft_wl_subtree.py:53\u001b[0m, in \u001b[0;36mSoft_WL_Subtree.cluster_subtrees\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcluster_subtrees\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# call \"export OMP_NUM_THREADS=1\" before running to avoid \"Too many memory regions\" error with Dask\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m    Cluster the subtrees\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    X: numpy array, shape = [n_samples, n_features]\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m    cluster_identities: numpy array, shape = [n_samples]\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     cluster_identities, _, _ \u001b[38;5;241m=\u001b[39m phenograph\u001b[38;5;241m.\u001b[39mcluster(X, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_job, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk)\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cluster_identities\n",
      "File \u001b[0;32m~/venv/cell-gnn/lib/python3.8/site-packages/phenograph/cluster.py:311\u001b[0m, in \u001b[0;36mcluster\u001b[0;34m(data, clustering_algo, k, directed, prune, min_cluster_size, jaccard, primary_metric, n_jobs, q_tol, louvain_time_limit, nn_method, partition_type, resolution_parameter, n_iterations, use_weights, seed, **kargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m idx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 311\u001b[0m     d, idx \u001b[38;5;241m=\u001b[39m \u001b[43mfind_neighbors\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprimary_metric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnn_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeighbors computed in \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m tic), flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    316\u001b[0m subtic \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/venv/cell-gnn/lib/python3.8/site-packages/phenograph/core.py:50\u001b[0m, in \u001b[0;36mfind_neighbors\u001b[0;34m(data, k, metric, p, method, n_jobs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinding \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m nearest neighbors using \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m metric and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m algorithm\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     45\u001b[0m         k, metric, algorithm\n\u001b[1;32m     46\u001b[0m     ),\n\u001b[1;32m     47\u001b[0m     flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m )\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkdtree\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 50\u001b[0m     nbrs \u001b[38;5;241m=\u001b[39m \u001b[43mNearestNeighbors\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# k+1 because results include self\u001b[39;49;00m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# use multiple cores if possible\u001b[39;49;00m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# primary metric\u001b[39;49;00m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# if metric == \"minkowski\", 2 --> euclidean, 1 --> manhattan\u001b[39;49;00m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgorithm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# kd_tree is fastest for minkowski metrics\u001b[39;49;00m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     d, idx \u001b[38;5;241m=\u001b[39m nbrs\u001b[38;5;241m.\u001b[39mkneighbors(data)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/venv/cell-gnn/lib/python3.8/site-packages/sklearn/neighbors/_unsupervised.py:176\u001b[0m, in \u001b[0;36mNearestNeighbors.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the nearest neighbors estimator from the training dataset.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \n\u001b[1;32m    161\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03m    The fitted nearest neighbors estimator.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/cell-gnn/lib/python3.8/site-packages/sklearn/neighbors/_base.py:491\u001b[0m, in \u001b[0;36mNeighborsBase._fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, (KDTree, BallTree, NeighborsBase)):\n\u001b[0;32m--> 491\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_algorithm_metric()\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/venv/cell-gnn/lib/python3.8/site-packages/sklearn/base.py:546\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 546\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    547\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/venv/cell-gnn/lib/python3.8/site-packages/sklearn/utils/validation.py:902\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    900\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    901\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 902\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    903\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    904\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    905\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    906\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    907\u001b[0m         )\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    912\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    913\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 37.2435518    7.58074535  80.02412017 ...  29.06080497  51.91345629\n 151.36154659].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "! export OMP_NUM_THREADS=1 # to avoid the insufficient memory error\n",
    "soft_wl_subtree_ = Soft_WL_Subtree(\n",
    "            n_iter=2, k=100\n",
    "        )\n",
    "Cell_graphs_prime, Signatures = soft_wl_subtree_.discover_patterns(Cell_graphs)\n",
    "print(\"There are {} discovered patterns\".format(len(Signatures)))\n",
    "cell_graph_prime = Cell_graphs_prime[0]\n",
    "print(\"The first Cell_graphs_prime element (and all others) is a tuple: (patient_id, adj, patterns)\")\n",
    "print(\"\\tThe first element is the patient id: {}\".format(cell_graph_prime[0]))\n",
    "print(\"\\tThe second element is the adjacnecy matrix, with the shape of {}\".format(cell_graph_prime[1].shape))\n",
    "print(\"\\tThe third element is the patterns, with the shape of {}\".format(cell_graph_prime[2].shape))\n",
    "print(\n",
    "        \"There are {} cells with {} unique patterns\".format(\n",
    "            cell_graph_prime[1].shape[0], np.unique(cell_graph_prime[2]).shape[0]\n",
    "        )\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cell-gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
